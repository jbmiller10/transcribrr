target_file: "app/controllers/gpt_controller.py"
test_file: "app/tests/test_gpt_controller.py"
current_issues:
  file_size: "912 lines - excessive for testing a 377-line controller"
  excessive_mocking:
    - "Mocks PyQt6 signals and threading at module level"
    - "Tests mock connections instead of actual behavior"
    - "Verifies exact constructor parameters rather than outcomes"
    - "Tests internal mock call sequences not business logic"
  structural_problems:
    - "Single monolithic test class with 50+ methods"
    - "Tests like test_signal_emission_order span 50 lines"
    - "Complex mock setups in setUp method"
    - "Tests implementation details not behavior"
  missing_coverage:
    - "No tests for actual OpenAI API error handling"
    - "No tests for thread lifecycle management"
    - "No tests for concurrent operations conflicts"
    - "No tests for resource cleanup on crashes"
    - "No integration tests with real components"

fix_plan:
  immediate_actions:
    - action: "Reduce file size from 912 to ~300 lines maximum"
      approach: "Focus only on core business logic tests"
      
    - action: "Remove excessive mocking"
      changes:
        - "Remove module-level PyQt6 mocking"
        - "Use dependency injection for testable components"
        - "Mock only external boundaries (OpenAI API, database)"
        - "Test actual signal flow not mock connections"
        
    - action: "Split into focused test files"
      new_structure:
        - "test_gpt_controller_validation.py - Input validation tests"
        - "test_gpt_controller_processing.py - Core processing logic"
        - "test_gpt_controller_error_handling.py - Error scenarios"
        - "test_gpt_controller_integration.py - Component integration"

  refactored_test_structure:
    test_gpt_controller.py:
      description: "Core unit tests for GPTController business logic"
      max_lines: 300
      test_classes:
        - class: "TestGPTControllerInitialization"
          focus: "Constructor and dependency injection"
          tests:
            - "test_init_with_db_manager"
            - "test_init_stores_dependencies"
            
        - class: "TestGPTProcessing"
          focus: "Core process method behavior"
          tests:
            - "test_process_validates_required_inputs"
            - "test_process_creates_thread_with_config"
            - "test_process_handles_api_key_retrieval"
            - "test_process_manages_thread_lifecycle"
            
        - class: "TestSmartFormat"
          focus: "Smart formatting behavior"
          tests:
            - "test_smart_format_uses_mini_model"
            - "test_smart_format_validates_text_input"
            - "test_smart_format_applies_html_formatting"
            
        - class: "TestRefinement"
          focus: "Text refinement logic"
          tests:
            - "test_refine_builds_message_chain"
            - "test_refine_preserves_original_transcript"
            - "test_refine_validates_all_inputs"

  testing_approach:
    principle: "Test behavior not implementation"
    
    good_test_example:
      name: "test_process_handles_api_errors"
      approach: |
        # Arrange
        controller = GPTController(mock_db)
        controller.get_api_key = lambda _: "test-key"
        mock_thread = Mock()
        mock_thread.start = Mock(side_effect=Exception("API Error"))
        controller._Thread = Mock(return_value=mock_thread)
        
        # Act
        result = controller.process(recording, prompt, config, callback)
        
        # Assert
        assert result is False  # Process failed
        assert "API Error" in controller.logger.error.call_args[0][0]
        assert len(controller.threads) == 0  # Thread cleaned up
        
    bad_test_example:
      name: "test_signal_connections"
      problem: "Tests mock connections not actual behavior"
      current: |
        # This tests implementation details
        mock_thread.completed.connect.assert_called_once()
        mock_thread.error.connect.assert_called_once()
        # Verifies HOW not WHAT
        
  new_test_scenarios:
    error_handling:
      - "API key rotation during processing"
      - "Thread crash with cleanup verification"
      - "Database write failures during completion"
      - "Callback exceptions don't crash controller"
      - "Network timeout handling"
      
    edge_cases:
      - "Very large transcripts (>100k chars)"
      - "Empty/whitespace-only inputs"
      - "Unicode and special characters in text"
      - "Concurrent operations on same recording"
      - "Thread cancellation during database write"
      
    resource_management:
      - "Thread cleanup on controller deletion"
      - "Busy guard lifecycle management"
      - "Memory usage with multiple threads"
      - "Signal disconnection on thread completion"

  mock_reduction_strategy:
    current_mocks: 15
    target_mocks: 4
    
    keep_mocking:
      - "OpenAI API calls (external service)"
      - "Database operations (I/O boundary)"
      - "get_api_key (security boundary)"
      - "Thread.start() (async boundary)"
      
    stop_mocking:
      - "PyQt6 signals - use real signal mechanism"
      - "QObject - use real inheritance"
      - "Recording model - use real dataclass"
      - "Config dictionaries - use real dicts"
      - "Callbacks - use real functions"
      - "Thread connections - test actual connections"
      
  test_helpers:
    fixtures:
      - name: "create_test_recording"
        purpose: "Factory for valid Recording objects"
        
      - name: "create_gpt_controller"
        purpose: "Factory with injectable dependencies"
        
      - name: "mock_openai_response"
        purpose: "Simulate API responses consistently"
        
    assertions:
      - name: "assert_thread_created"
        checks:
          - "Thread exists in controller.threads"
          - "Thread has correct configuration"
          - "Busy guard is active"
          
      - name: "assert_thread_cleaned_up"
        checks:
          - "Thread removed from controller.threads"
          - "Busy guard released"
          - "Signals disconnected"

  quality_metrics:
    target:
      - "Test file < 300 lines"
      - "No test method > 20 lines"
      - "Mock usage < 30% of test code"
      - "100% of public methods tested"
      - "All error paths covered"
      - "Test execution < 2 seconds"
      
    avoid:
      - "Testing mock.assert_called_with()"
      - "Verifying internal state directly"
      - "Testing Python/Qt framework behavior"
      - "Complex mock configuration"
      - "Monolithic test classes"

  implementation_order:
    week_1:
      - "Remove module-level mocking"
      - "Split into focused test files"
      - "Reduce each file to <300 lines"
      
    week_2:
      - "Add missing error scenarios"
      - "Add edge case tests"
      - "Implement test helpers"
      
    week_3:
      - "Add integration tests"
      - "Performance benchmarks"
      - "Documentation"

  example_refactored_test:
    description: "Example of properly focused behavior test"
    # Completed: Added behavior tests for process, smart_format, refine, errors, and cancel.
    code: |
      class TestGPTProcessing(unittest.TestCase):
          def setUp(self):
              self.db_manager = Mock()
              self.controller = GPTController(self.db_manager)
              self.controller.get_api_key = Mock(return_value="test-key")
              
          def test_process_validates_recording_has_transcript(self):
              """Process should fail gracefully when recording lacks transcript."""
              # Arrange
              empty_recording = Recording(id=1, raw_transcript="")
              
              # Act
              result = self.controller.process(
                  empty_recording, 
                  "prompt", 
                  {}, 
                  Mock()
              )
              
              # Assert
              self.assertFalse(result)
              self.assertEqual(len(self.controller.threads), 0)
              
          def test_process_handles_thread_creation_failure(self):
              """Process should handle thread creation exceptions."""
              # Arrange
              recording = Recording(id=1, raw_transcript="test")
              self.controller._Thread = Mock(side_effect=MemoryError())
              
              # Act & Assert
              with self.assertLogs('transcribrr', level='ERROR'):
                  result = self.controller.process(
                      recording,
                      "prompt",
                      {},
                      Mock()
                  )
                  
              self.assertFalse(result)
              self.assertEqual(len(self.controller.threads), 0)

success_criteria:
  - "Tests complete in < 2 seconds"
  - "No false positives on CI"
  - "Clear failure messages"
  - "Easy to add new test cases"
  - "Maintainable alongside production code"
